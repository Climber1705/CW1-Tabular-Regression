{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d377d13b",
      "metadata": {},
      "source": [
        "# Tuning Hyperparameters\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae4a06d8",
      "metadata": {},
      "source": [
        "## 1. Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2774e08e",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a014654",
      "metadata": {},
      "source": [
        "## 2. Data Loading and Preprocessing\n",
        "\n",
        "Load the training data and apply initial filtering to remove invalid entries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc51062b",
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"../data/CW1_train.csv\")\n",
        "# Remove physically impossible dimensions identified in the EDA\n",
        "df = df[(df[\"x\"] > 0) & (df[\"y\"] > 0) & (df[\"z\"] > 0) & (df[\"y\"] <= 10)]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd39a874",
      "metadata": {},
      "source": [
        "Separate features and target variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74d93e89",
      "metadata": {},
      "outputs": [],
      "source": [
        "X = df.drop(columns=[\"outcome\"])\n",
        "Y = df[\"outcome\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d828e7a6",
      "metadata": {},
      "source": [
        "## 3. Feature Engineering\n",
        "\n",
        "Create derived features including volume and log-transformed price and carat features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "892194d9",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "def feature_engineering(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    df[\"volume\"] = df[\"x\"] * df[\"y\"] * df[\"z\"]\n",
        "    df[\"log_price\"] = np.log1p(df[\"price\"])\n",
        "    df[\"log_carat\"] = np.log1p(df[\"carat\"])\n",
        "    return df.drop(columns=[\"x\", \"y\", \"z\", \"carat\", \"price\"])\n",
        "\n",
        "feature_engineering_transformer = FunctionTransformer(\n",
        "    feature_engineering,\n",
        "    validate=False,\n",
        "    check_inverse=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f523af21",
      "metadata": {},
      "source": [
        "## 4. Preprocessing Pipeline\n",
        "\n",
        "Build a preprocessor that standardizes numerical features and encodes categorical features using ordinal encoding with predefined orderings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2a05860",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
        "from sklearn.compose import ColumnTransformer, make_column_selector\n",
        "\n",
        "cut_order = [\"Fair\", \"Good\", \"Very Good\", \"Premium\", \"Ideal\"]\n",
        "colour_order = [\"J\", \"I\", \"H\", \"G\", \"F\", \"E\", \"D\"]\n",
        "clarity_order = [\"I1\", \"SI2\", \"SI1\", \"VS2\", \"VS1\", \"VVS2\", \"VVS1\", \"IF\"]\n",
        "\n",
        "def build_preprocessor() -> ColumnTransformer:\n",
        "    categorical_columns = [\"cut\", \"color\", \"clarity\"]\n",
        "\n",
        "    return ColumnTransformer(\n",
        "        transformers=[\n",
        "            (\"num\", StandardScaler(), make_column_selector(dtype_include=np.number)),\n",
        "            (\"cat\", OrdinalEncoder(categories=[cut_order, colour_order, clarity_order]), categorical_columns),\n",
        "        ],\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a06d8cd8",
      "metadata": {},
      "source": [
        "Create a pipeline that combines feature engineering, preprocessing, and the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71696b0f",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.base import BaseEstimator\n",
        "\n",
        "def build_pipeline(model: BaseEstimator) -> Pipeline:\n",
        "    return Pipeline(steps=[\n",
        "        (\"feature_engineering\", feature_engineering_transformer),\n",
        "        (\"preprocessor\", build_preprocessor()),\n",
        "        (\"model\", model)\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4ad6b34",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, KFold\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from xgboost import XGBRegressor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b4dd160",
      "metadata": {},
      "outputs": [],
      "source": [
        "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Broad Search\n",
        "rf_params = {\n",
        "    \"model__n_estimators\": np.arange(100, 600, 50),\n",
        "    \"model__max_depth\": np.arange(3, 20),\n",
        "    \"model__min_samples_split\": np.arange(2, 10),\n",
        "    \"model__min_samples_leaf\": np.arange(1, 6),\n",
        "}\n",
        "\n",
        "gb_params = {\n",
        "    \"model__n_estimators\": np.arange(100, 600, 50),\n",
        "    \"model__learning_rate\": np.linspace(0.01, 0.3, 20),\n",
        "    \"model__max_depth\": np.arange(2, 10),\n",
        "    \"model__subsample\": np.linspace(0.6, 1.0, 10),\n",
        "}\n",
        "\n",
        "xgb_params = {\n",
        "    \"model__n_estimators\": np.arange(100, 600, 50),\n",
        "    \"model__learning_rate\": np.linspace(0.01, 0.3, 20),\n",
        "    \"model__max_depth\": np.arange(3, 12),\n",
        "    \"model__subsample\": np.linspace(0.6, 1.0, 10),\n",
        "    \"model__colsample_bytree\": np.linspace(0.6, 1.0, 10),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d756677f",
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_random_search(model, param_dist, name):\n",
        "    pipeline = build_pipeline(model)\n",
        "\n",
        "    random_search = RandomizedSearchCV(\n",
        "        pipeline,\n",
        "        param_distributions=param_dist,\n",
        "        n_iter=40,\n",
        "        cv=cv,\n",
        "        scoring=\"r2\",\n",
        "        n_jobs=-1,\n",
        "        verbose=1,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    random_search.fit(X, Y)\n",
        "\n",
        "    print(f\"\\n{name} Random Search Best R²: {random_search.best_score_:.4f}\")\n",
        "    print(f\"{name} Best Params: {random_search.best_params_}\")\n",
        "\n",
        "    return random_search\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d634ba43",
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_local_grid(best_params):\n",
        "    grid = {}\n",
        "\n",
        "    for param, value in best_params.items():\n",
        "        if isinstance(value, int):\n",
        "            grid[param] = [max(1, value - 50), value, value + 50]\n",
        "        elif isinstance(value, float):\n",
        "            grid[param] = [round(value * 0.8, 3), value, round(value * 1.2, 3)]\n",
        "        else:\n",
        "            grid[param] = [value]\n",
        "\n",
        "    return grid\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91e61208",
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_grid_search(random_search, name):\n",
        "    local_grid = build_local_grid(random_search.best_params_)\n",
        "\n",
        "    print(f\"\\n{name} Local Grid:\")\n",
        "    print(local_grid)\n",
        "\n",
        "    grid_search = GridSearchCV(\n",
        "        random_search.estimator,\n",
        "        param_grid=local_grid,\n",
        "        cv=cv,\n",
        "        scoring=\"r2\",\n",
        "        n_jobs=-1,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    grid_search.fit(X, Y)\n",
        "\n",
        "    print(f\"\\n{name} Grid Search Best R²: {grid_search.best_score_:.4f}\")\n",
        "    print(f\"{name} Fine Params: {grid_search.best_params_}\")\n",
        "\n",
        "    return grid_search\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29d4fa57",
      "metadata": {},
      "outputs": [],
      "source": [
        "rf_random = run_random_search(RandomForestRegressor(random_state=42), rf_params, \"Random Forest\")\n",
        "gb_random = run_random_search(GradientBoostingRegressor(random_state=42), gb_params, \"Gradient Boosting\")\n",
        "xgb_random = run_random_search(XGBRegressor(random_state=42, verbosity=0), xgb_params, \"XGBoost\")\n",
        "\n",
        "rf_grid = run_grid_search(rf_random, \"Random Forest\")\n",
        "gb_grid = run_grid_search(gb_random, \"Gradient Boosting\")\n",
        "xgb_grid = run_grid_search(xgb_random, \"XGBoost\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa888721",
      "metadata": {},
      "outputs": [],
      "source": [
        "final_results = pd.DataFrame({\n",
        "    \"Model\": [\"Random Forest\", \"Gradient Boosting\", \"XGBoost\"],\n",
        "    \"Fine-tuned R²\": [\n",
        "        rf_grid.best_score_,\n",
        "        gb_grid.best_score_,\n",
        "        xgb_grid.best_score_,\n",
        "    ]\n",
        "}).sort_values(\"Fine-tuned R²\", ascending=False)\n",
        "\n",
        "final_results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58ecffff",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.barh(final_results[\"Model\"], final_results[\"Fine-tuned R²\"])\n",
        "plt.xlabel(\"Fine-tuned Cross-Validated R²\")\n",
        "plt.title(\"Final Tuned Model Comparison\")\n",
        "plt.gca().invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"../figures/final_tuned_models.png\", dpi=300)\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
